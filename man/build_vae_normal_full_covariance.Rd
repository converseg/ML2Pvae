% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/build_vae_normal_full_covariance.R
\name{build_vae_normal_full_covariance}
\alias{build_vae_normal_full_covariance}
\title{Build a VAE that fits to a normal, full covariance N(m,S) latent distribution}
\usage{
build_vae_normal_full_covariance(num_items, num_skills, Q_matrix,
  mean_vector = rep(0, num_skills),
  covariance_matrix = diag(num_skills), enc_hid_arch = c(10),
  hid_enc_activations = rep("sigmoid", length(enc_hid_arch)),
  output_activation = "sigmoid", kl_weight = 1)
}
\arguments{
\item{num_items}{the number of items on the assessment; also the number of nodes in the input/output layers of the VAE}

\item{num_skills}{the number of skills being evaluated; also the size of the distribution learned by the VAE}

\item{Q_matrix}{a binary, \code{num_skills} by \code{num_items} matrix relating the assessment items with skills}

\item{mean_vector}{a vector of length \code{num_skills} specifying the mean of each latent trait}

\item{covariance_matrix}{a symmetric, positive definite, \code{num_skills} by \code{num_skills}, matrix giving the covariance of the latent traits}

\item{enc_hid_arch}{a vector detailing the number an size of hidden layers in the encoder}

\item{hid_enc_activations}{a vector specifying the activation function in each hidden layer in the encoder; must be the same length as \code{enc_hid_arch}}

\item{kl_weight}{an optional weight for the KL divergence term in the loss function}
}
\value{
Returns three keras models: the encoder, decoder, and vae.
}
\description{
Build a VAE that fits to a normal, full covariance N(m,S) latent distribution
}
\examples{
Q <- matrix(c(1,0,1,1,0,1,1,0), nrow = 2, ncol = 4)
cov <- matrix(c(.7,.3,.3,1), nrow = 2, ncol = 2)
models <- build_vae_normal_full_covariance(4, 2, Q,
          mean_vector = c(-0.5, 0), covariance_matrix = cov,
          enc_hid_arch = c(6, 3), hid_enc_activation = c('sigmoid', 'relu'),
          output_activation = 'tanh',
          kl_weight = 0.1)
models <- build_vae_normal_full_covariance(4, 2, Q)
vae <- models[[3]]

TODO: There seems to be a bad calculation somewhere when we do batches. the results are good when
batch size is 1, 2, 4 (tiny bit worse), but get pretty bad if batch size is 64, 32, 16 (ehhh), 8 (better).
If there is a bug, it is likely in sampling, not loss (since batch tests work)
}
